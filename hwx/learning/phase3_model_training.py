# ğŸ¯ ç¬¬ä¸‰é˜¶æ®µï¼šè®­ç»ƒæ¨¡å‹ (ç¬¬5-6å‘¨)
# å­¦ä¹ ç›®æ ‡ï¼šå­¦ä¼šè®­ç»ƒæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œèƒ½å¤Ÿè¿›è¡Œé¢„æµ‹

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.multioutput import MultiOutputRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
import warnings
warnings.filterwarnings('ignore')

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

def load_data_with_features():
    """åŠ è½½å¸¦æœ‰ç‰¹å¾çš„æ•°æ®"""
    print("ğŸ“Š æ­£åœ¨åŠ è½½å¸¦æœ‰ç‰¹å¾çš„æ•°æ®...")
    
    # å°è¯•åŠ è½½å·²ç»å¤„ç†è¿‡çš„æ•°æ®
    feature_file = 'image/train_labels_with_features.csv'
    if os.path.exists(feature_file):
        print(f"âœ… æ‰¾åˆ°ç‰¹å¾æ–‡ä»¶: {feature_file}")
        df = pd.read_csv(feature_file)
    else:
        print("âš ï¸ æœªæ‰¾åˆ°ç‰¹å¾æ–‡ä»¶ï¼Œå°è¯•åŠ è½½åŸå§‹æ•°æ®...")
        try:
            df = pd.read_csv('../../data/train_labels.csv')
            print("âœ… æˆåŠŸåŠ è½½åŸå§‹æ•°æ®")
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
            return None, None
    
    # è·å–ç›®æ ‡å˜é‡åˆ—
    target_columns = [col for col in df.columns if col.startswith('target_')]
    print(f"ğŸ¯ æ‰¾åˆ° {len(target_columns)} ä¸ªç›®æ ‡å˜é‡")
    
    return df, target_columns

def prepare_features_and_targets(df, target_columns):
    """å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡"""
    print("\n" + "=" * 50)
    print("ğŸ”§ å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡")
    print("=" * 50)
    
    # é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆæ’é™¤ç›®æ ‡å˜é‡å’Œæ—¥æœŸåˆ—ï¼‰
    feature_columns = [col for col in df.columns 
                      if col not in target_columns and col != 'date_id']
    
    print(f"ğŸ“Š ç‰¹å¾åˆ—æ•°é‡: {len(feature_columns)}")
    print(f"ğŸ¯ ç›®æ ‡å˜é‡æ•°é‡: {len(target_columns)}")
    
    # å¤„ç†ç¼ºå¤±å€¼
    print("\nğŸ” å¤„ç†ç¼ºå¤±å€¼...")
    initial_missing = df[feature_columns + target_columns].isnull().sum().sum()
    print(f"åˆå§‹ç¼ºå¤±å€¼æ€»æ•°: {initial_missing}")
    
    # å¯¹äºç‰¹å¾åˆ—ï¼Œç”¨0å¡«å……ç¼ºå¤±å€¼
    df[feature_columns] = df[feature_columns].fillna(0)
    
    # å¯¹äºç›®æ ‡å˜é‡ï¼Œåˆ é™¤æœ‰ç¼ºå¤±å€¼çš„è¡Œ
    df_clean = df.dropna(subset=target_columns)
    
    final_missing = df_clean[feature_columns + target_columns].isnull().sum().sum()
    print(f"å¤„ç†åç¼ºå¤±å€¼æ€»æ•°: {final_missing}")
    print(f"æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
    
    # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
    X = df_clean[feature_columns]
    y = df_clean[target_columns]
    
    print(f"âœ… ç‰¹å¾çŸ©é˜µå½¢çŠ¶: {X.shape}")
    print(f"âœ… ç›®æ ‡å˜é‡å½¢çŠ¶: {y.shape}")
    
    return X, y, feature_columns

def train_simple_model(X, y, target_name):
    """ä»»åŠ¡1ï¼šè®­ç»ƒç®€å•æ¨¡å‹"""
    print(f"\nğŸ¯ è®­ç»ƒç®€å•æ¨¡å‹: {target_name}")
    print("-" * 40)
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=False  # æ—¶é—´åºåˆ—æ•°æ®ä¸æ‰“ä¹±
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape}")
    print(f"éªŒè¯é›†å¤§å°: {X_val.shape}")
    
    # åˆ›å»ºæ¨¡å‹
    model = RandomForestRegressor(
        n_estimators=100, 
        random_state=42,
        n_jobs=-1,  # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ
        verbose=0
    )
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹...")
    
    # è®­ç»ƒæ¨¡å‹
    model.fit(X_train, y_train)
    
    print("âœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    
    # é¢„æµ‹
    y_pred = model.predict(X_val)
    
    # è¯„ä¼°
    mse = mean_squared_error(y_val, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_val, y_pred)
    r2 = r2_score(y_val, y_pred)
    
    print(f"ğŸ“Š æ¨¡å‹æ€§èƒ½è¯„ä¼°:")
    print(f"  MSE: {mse:.6f}")
    print(f"  RMSE: {rmse:.6f}")
    print(f"  MAE: {mae:.6f}")
    print(f"  RÂ²: {r2:.6f}")
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    print(f"\nğŸ† å‰10ä¸ªé‡è¦ç‰¹å¾:")
    print(feature_importance.head(10))
    
    return model, {
        'mse': mse,
        'rmse': rmse,
        'mae': mae,
        'r2': r2,
        'feature_importance': feature_importance
    }

def train_multi_output_model(X, y):
    """ä»»åŠ¡2ï¼šå¤šç›®æ ‡é¢„æµ‹"""
    print("\n" + "=" * 50)
    print("ğŸ¯ ä»»åŠ¡2ï¼šå¤šç›®æ ‡é¢„æµ‹")
    print("=" * 50)
    
    # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=0.2, random_state=42, shuffle=False
    )
    
    print(f"è®­ç»ƒé›†å¤§å°: {X_train.shape}")
    print(f"éªŒè¯é›†å¤§å°: {X_val.shape}")
    
    # åˆ›å»ºå¤šè¾“å‡ºéšæœºæ£®æ—
    base_model = RandomForestRegressor(
        n_estimators=100, 
        random_state=42,
        n_jobs=-1,
        verbose=0
    )
    
    multi_model = MultiOutputRegressor(base_model)
    
    print("ğŸš€ å¼€å§‹è®­ç»ƒå¤šè¾“å‡ºæ¨¡å‹...")
    
    # è®­ç»ƒæ¨¡å‹
    multi_model.fit(X_train, y_train)
    
    print("âœ… å¤šè¾“å‡ºæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    
    # é¢„æµ‹
    y_pred = multi_model.predict(X_val)
    
    # è¯„ä¼°æ¯ä¸ªç›®æ ‡å˜é‡
    print("\nğŸ“Š å¤šè¾“å‡ºæ¨¡å‹æ€§èƒ½è¯„ä¼°:")
    
    results = {}
    for i, target_name in enumerate(y.columns):
        target_actual = y_val.iloc[:, i]
        target_pred = y_pred[:, i]
        
        mse = mean_squared_error(target_actual, target_pred)
        rmse = np.sqrt(mse)
        mae = mean_absolute_error(target_actual, target_pred)
        r2 = r2_score(target_actual, target_pred)
        
        results[target_name] = {
            'mse': mse,
            'rmse': rmse,
            'mae': mae,
            'r2': r2
        }
        
        print(f"\n{target_name}:")
        print(f"  RMSE: {rmse:.6f}")
        print(f"  MAE: {mae:.6f}")
        print(f"  RÂ²: {r2:.6f}")
    
    # è®¡ç®—å¹³å‡æ€§èƒ½
    avg_rmse = np.mean([results[target]['rmse'] for target in results])
    avg_r2 = np.mean([results[target]['r2'] for target in results])
    
    print(f"\nğŸ† å¹³å‡æ€§èƒ½:")
    print(f"  å¹³å‡RMSE: {avg_rmse:.6f}")
    print(f"  å¹³å‡RÂ²: {avg_r2:.6f}")
    
    return multi_model, results

def compare_models(single_results, multi_results):
    """æ¯”è¾ƒå•ç›®æ ‡å’Œå¤šç›®æ ‡æ¨¡å‹"""
    print("\n" + "=" * 50)
    print("ğŸ” æ¨¡å‹æ¯”è¾ƒåˆ†æ")
    print("=" * 50)
    
    try:
        # æ£€æŸ¥æ•°æ®ç»“æ„å¹¶å®‰å…¨åœ°æå–æ•°æ®
        if isinstance(single_results, dict) and len(single_results) > 0:
            first_target = list(single_results.keys())[0]
            
            # å®‰å…¨åœ°æå–RMSEå€¼
            if isinstance(single_results[first_target], dict) and 'rmse' in single_results[first_target]:
                single_rmse = single_results[first_target]['rmse']
            else:
                single_rmse = single_results[first_target] if isinstance(single_results[first_target], (int, float)) else 0
                
            if isinstance(multi_results, dict) and len(multi_results) > 0:
                if isinstance(multi_results[first_target], dict) and 'rmse' in multi_results[first_target]:
                    multi_rmse = multi_results[first_target]['rmse']
                else:
                    multi_rmse = multi_results[first_target] if isinstance(multi_results[first_target], (int, float)) else 0
            else:
                multi_rmse = multi_results if isinstance(multi_results, (int, float)) else 0
            
            print(f"ğŸ“Š æ¯”è¾ƒ {first_target} çš„é¢„æµ‹æ€§èƒ½:")
            print(f"å•ç›®æ ‡æ¨¡å‹ RMSE: {single_rmse:.6f}")
            print(f"å¤šç›®æ ‡æ¨¡å‹ RMSE: {multi_rmse:.6f}")
            
            if single_rmse > 0 and multi_rmse > 0:
                if single_rmse < multi_rmse:
                    print("ğŸ† å•ç›®æ ‡æ¨¡å‹è¡¨ç°æ›´å¥½")
                else:
                    print("ğŸ† å¤šç›®æ ‡æ¨¡å‹è¡¨ç°æ›´å¥½")
                    
                # è®¡ç®—æ€§èƒ½æå‡
                improvement = ((single_rmse - multi_rmse) / single_rmse) * 100
                print(f"æ€§èƒ½æå‡: {improvement:.2f}%")
            else:
                print("âš ï¸  æ— æ³•æ¯”è¾ƒæ¨¡å‹æ€§èƒ½ï¼ˆRMSEå€¼å¼‚å¸¸ï¼‰")
        else:
            print("âš ï¸  å•ç›®æ ‡æ¨¡å‹ç»“æœä¸ºç©ºæˆ–æ ¼å¼å¼‚å¸¸")
            return
            
        # å¯è§†åŒ–æ¯”è¾ƒ
        try:
            # å‡†å¤‡æ¯”è¾ƒæ•°æ®
            if isinstance(single_results, dict) and isinstance(multi_results, dict):
                targets = list(single_results.keys())[:5]  # åªæ¯”è¾ƒå‰5ä¸ª
                
                single_rmse_list = []
                multi_rmse_list = []
                
                for target in targets:
                    # å®‰å…¨åœ°æå–RMSEå€¼
                    if isinstance(single_results[target], dict) and 'rmse' in single_results[target]:
                        single_rmse_list.append(single_results[target]['rmse'])
                    else:
                        single_rmse_list.append(single_results[target] if isinstance(single_results[target], (int, float)) else 0)
                        
                    if isinstance(multi_results[target], dict) and 'rmse' in multi_results[target]:
                        multi_rmse_list.append(multi_results[target]['rmse'])
                    else:
                        multi_rmse_list.append(multi_results[target] if isinstance(multi_results[target], (int, float)) else 0)
            else:
                # å¦‚æœç»“æœä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œä½¿ç”¨ç®€å•çš„æ¯”è¾ƒ
                targets = ['æ¨¡å‹1', 'æ¨¡å‹2']
                single_rmse_list = [single_rmse]
                multi_rmse_list = [multi_rmse]
            
            # åˆ›å»ºæ¯”è¾ƒå›¾è¡¨
            x = np.arange(len(targets))
            width = 0.35
            
            fig, ax = plt.subplots(figsize=(12, 6))
            rects1 = ax.bar(x - width/2, single_rmse_list, width, label='å•ç›®æ ‡æ¨¡å‹', alpha=0.8, color='skyblue')
            rects2 = ax.bar(x + width/2, multi_rmse_list, width, label='å¤šç›®æ ‡æ¨¡å‹', alpha=0.8, color='lightcoral')
            
            ax.set_xlabel('ç›®æ ‡å˜é‡')
            ax.set_ylabel('RMSE')
            ax.set_title('å•ç›®æ ‡ vs å¤šç›®æ ‡æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ')
            ax.set_xticks(x)
            ax.set_xticklabels(targets, rotation=45)
            ax.legend()
            
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            def autolabel(rects):
                for rect in rects:
                    height = rect.get_height()
                    ax.annotate(f'{height:.4f}',
                               xy=(rect.get_x() + rect.get_width() / 2, height),
                               xytext=(0, 3),
                               textcoords="offset points",
                               ha='center', va='bottom')
            
            autolabel(rects1)
            autolabel(rects2)
            
            plt.tight_layout()
            plt.show()
            
            # ä¿å­˜å›¾è¡¨
            plt.savefig('image/model_comparison.png', dpi=300, bbox_inches='tight')
            print("ğŸ’¾ æ¨¡å‹æ¯”è¾ƒå›¾è¡¨å·²ä¿å­˜ä¸º 'image/model_comparison.png'")
            
        except Exception as e:
            print(f"âŒ å¯è§†åŒ–æ¯”è¾ƒå¤±è´¥: {e}")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¯”è¾ƒåˆ†æå¤±è´¥: {e}")
        print("ç»§ç»­æ‰§è¡Œå…¶ä»–åŠŸèƒ½...")

def cross_validation_analysis(X, y, n_splits=5):
    """äº¤å‰éªŒè¯åˆ†æ"""
    print("\n" + "=" * 50)
    print("ğŸ”„ äº¤å‰éªŒè¯åˆ†æ")
    print("=" * 50)
    
    # ä½¿ç”¨éšæœºæ£®æ—è¿›è¡Œäº¤å‰éªŒè¯
    model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)
    
    print("ğŸš€ å¼€å§‹äº¤å‰éªŒè¯...")
    
    # å¯¹æ¯ä¸ªç›®æ ‡å˜é‡è¿›è¡Œäº¤å‰éªŒè¯
    cv_scores = {}
    for i, target_name in enumerate(y.columns[:5]):  # åªéªŒè¯å‰5ä¸ªç›®æ ‡å˜é‡
        target_values = y.iloc[:, i]
        
        # åˆ é™¤ç›®æ ‡å˜é‡ä¸­çš„ç¼ºå¤±å€¼
        valid_indices = ~target_values.isnull()
        X_valid = X[valid_indices]
        y_valid = target_values[valid_indices]
        
        if len(X_valid) > 0:
            scores = cross_val_score(model, X_valid, y_valid, 
                                   cv=n_splits, scoring='neg_mean_squared_error')
            rmse_scores = np.sqrt(-scores)
            
            cv_scores[target_name] = {
                'mean_rmse': rmse_scores.mean(),
                'std_rmse': rmse_scores.std(),
                'scores': rmse_scores
            }
            
            print(f"{target_name}: å¹³å‡RMSE = {rmse_scores.mean():.6f} Â± {rmse_scores.std():.6f}")
    
    return cv_scores

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å•†å“é¢„æµ‹æŒ‘æˆ˜èµ› - å°ç™½å­¦ä¹ æŒ‡å—")
    print("ğŸ“š ç¬¬ä¸‰é˜¶æ®µï¼šæ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    df, target_columns = load_data_with_features()
    if df is None:
        return
    
    # å‡†å¤‡ç‰¹å¾å’Œç›®æ ‡å˜é‡
    X, y, feature_columns = prepare_features_and_targets(df, target_columns)
    if X is None:
        return
    
    # ä»»åŠ¡1ï¼šè®­ç»ƒç®€å•æ¨¡å‹ï¼ˆé€‰æ‹©ç¬¬ä¸€ä¸ªç›®æ ‡å˜é‡ï¼‰
    print(f"\nğŸ¯ é€‰æ‹©ç¬¬ä¸€ä¸ªç›®æ ‡å˜é‡è¿›è¡Œå•ç›®æ ‡è®­ç»ƒ: {target_columns[0]}")
    single_model, single_results = train_simple_model(X, y.iloc[:, 0], target_columns[0])
    
    # ä»»åŠ¡2ï¼šå¤šç›®æ ‡é¢„æµ‹
    multi_model, multi_results = train_multi_output_model(X, y)
    
    # æ¯”è¾ƒæ¨¡å‹æ€§èƒ½ - ç¡®ä¿æ•°æ®ç»“æ„ä¸€è‡´
    if single_results is not None and multi_results is not None:
        compare_models(single_results, multi_results)
    else:
        print("âš ï¸  è·³è¿‡æ¨¡å‹æ¯”è¾ƒï¼ˆæ¨¡å‹è®­ç»ƒç»“æœä¸ºç©ºï¼‰")
    
    # äº¤å‰éªŒè¯åˆ†æ
    cv_scores = cross_validation_analysis(X, y)
    
    # ä¿å­˜æ¨¡å‹
    import joblib
    
    # ä¿å­˜å•ç›®æ ‡æ¨¡å‹
    joblib.dump(single_model, 'image/single_target_model.pkl')
    print("\nğŸ’¾ å•ç›®æ ‡æ¨¡å‹å·²ä¿å­˜ä¸º 'image/single_target_model.pkl'")
    
    # ä¿å­˜å¤šç›®æ ‡æ¨¡å‹
    joblib.dump(multi_model, 'image/multi_target_model.pkl')
    print("ğŸ’¾ å¤šç›®æ ‡æ¨¡å‹å·²ä¿å­˜ä¸º 'image/multi_target_model.pkl'")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç¬¬ä¸‰é˜¶æ®µå­¦ä¹ ä»»åŠ¡å®Œæˆï¼")
    print("ğŸ“ æ¥ä¸‹æ¥ä½ å¯ä»¥ï¼š")
    print("   1. åˆ†ææ¨¡å‹æ€§èƒ½ç»“æœ")
    print("   2. æŸ¥çœ‹ç‰¹å¾é‡è¦æ€§")
    print("   3. å‡†å¤‡è¿›å…¥ç¬¬å››é˜¶æ®µï¼šæ·±åº¦å­¦ä¹ ")
    print("=" * 60)

if __name__ == "__main__":
    main()
