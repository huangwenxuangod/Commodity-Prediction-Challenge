# ğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šåˆ›å»ºç‰¹å¾ (ç¬¬3-4å‘¨)
# å­¦ä¹ ç›®æ ‡ï¼šå­¦ä¼šä»åŸå§‹æ•°æ®ä¸­æå–æœ‰ç”¨ä¿¡æ¯ï¼Œåˆ›å»ºèƒ½å¤Ÿå¸®åŠ©é¢„æµ‹çš„ç‰¹å¾

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import sys
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

def load_data():
    """åŠ è½½æ•°æ®"""
    print("ğŸ“Š æ­£åœ¨åŠ è½½æ•°æ®...")
    try:
        train_labels = pd.read_csv('../data/train_labels.csv')
        print(f"âœ… æˆåŠŸåŠ è½½è®­ç»ƒæ ‡ç­¾æ•°æ®ï¼Œå½¢çŠ¶: {train_labels.shape}")
        return train_labels
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return None

def create_time_features(df):
    """ä»»åŠ¡1ï¼šåˆ›å»ºæ—¶é—´ç‰¹å¾"""
    print("\n" + "=" * 50)
    print("â° ä»»åŠ¡1ï¼šåˆ›å»ºæ—¶é—´ç‰¹å¾")
    print("=" * 50)
    
    # ç¡®ä¿date_idæ˜¯æ—¥æœŸç±»å‹
    if 'date_id' in df.columns:
        if df['date_id'].dtype == 'object':
            df['date_id'] = pd.to_datetime(df['date_id'])
        elif df['date_id'].dtype == 'int64':
            # å¦‚æœæ˜¯æ•´æ•°ï¼Œå‡è®¾æ˜¯æ—¥æœŸIDï¼Œè½¬æ¢ä¸ºæ—¥æœŸ
            df['date_id'] = pd.to_datetime(df['date_id'], unit='D', origin='1970-01-01')
        
        print("ğŸ“… åˆ›å»ºåŸºç¡€æ—¶é—´ç‰¹å¾...")
        
        # åŸºç¡€æ—¶é—´ç‰¹å¾
        df['year'] = df['date_id'].dt.year
        df['month'] = df['date_id'].dt.month
        df['day_of_week'] = df['date_id'].dt.dayofweek
        df['quarter'] = df['date_id'].dt.quarter
        df['day_of_year'] = df['date_id'].dt.dayofyear
        
        # å­£èŠ‚æ€§ç‰¹å¾
        df['is_quarter_start'] = df['date_id'].dt.is_quarter_start.astype(int)
        df['is_quarter_end'] = df['date_id'].dt.is_quarter_end.astype(int)
        df['is_month_start'] = df['date_id'].dt.is_month_start.astype(int)
        df['is_month_end'] = df['date_id'].dt.is_month_end.astype(int)
        
        # å‘¨æœŸæ€§ç‰¹å¾
        df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)
        df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)
        df['sin_day_of_week'] = np.sin(2 * np.pi * df['day_of_week'] / 7)
        df['cos_day_of_week'] = np.cos(2 * np.pi * df['day_of_week'] / 7)
        
        print("âœ… æ—¶é—´ç‰¹å¾åˆ›å»ºå®Œæˆï¼")
        print(f"æ–°å¢ç‰¹å¾æ•°é‡: {len([col for col in df.columns if col in ['year', 'month', 'day_of_week', 'quarter', 'day_of_year', 'is_quarter_start', 'is_quarter_end', 'is_month_start', 'is_month_end', 'sin_month', 'cos_month', 'sin_day_of_week', 'cos_day_of_week']])}")
        
        return df
    else:
        print("âš ï¸ æœªæ‰¾åˆ°date_idåˆ—ï¼Œè·³è¿‡æ—¶é—´ç‰¹å¾åˆ›å»º")
        return df

def create_lag_features(df, target_cols, lags=[1, 2, 3, 5, 10]):
    """ä»»åŠ¡2ï¼šåˆ›å»ºæ»åç‰¹å¾"""
    print("\n" + "=" * 50)
    print("ğŸ”„ ä»»åŠ¡2ï¼šåˆ›å»ºæ»åç‰¹å¾")
    print("=" * 50)
    
    if not target_cols:
        print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡å˜é‡ï¼Œè·³è¿‡æ»åç‰¹å¾åˆ›å»º")
        return df
    
    print(f"ğŸ¯ ä¸ºç›®æ ‡å˜é‡åˆ›å»ºæ»åç‰¹å¾ï¼Œæ»åæœŸæ•°: {lags}")
    
    # æŒ‰æ—¥æœŸæ’åºï¼ˆå¦‚æœæœ‰date_idåˆ—ï¼‰
    if 'date_id' in df.columns:
        df = df.sort_values('date_id').reset_index(drop=True)
    
    new_features_count = 0
    
    for col in target_cols:
        for lag in lags:
            feature_name = f'{col}_lag_{lag}'
            df[feature_name] = df[col].shift(lag)
            new_features_count += 1
    
    print(f"âœ… æ»åç‰¹å¾åˆ›å»ºå®Œæˆï¼æ–°å¢ç‰¹å¾æ•°é‡: {new_features_count}")
    
    return df

def create_statistical_features(df, target_cols, windows=[5, 10, 20]):
    """åˆ›å»ºç»Ÿè®¡ç‰¹å¾"""
    print("\n" + "=" * 50)
    print("ğŸ“Š åˆ›å»ºç»Ÿè®¡ç‰¹å¾")
    print("=" * 50)
    
    if not target_cols:
        print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡å˜é‡ï¼Œè·³è¿‡ç»Ÿè®¡ç‰¹å¾åˆ›å»º")
        return df
    
    print(f"ğŸ“ˆ åˆ›å»ºæ»‘åŠ¨çª—å£ç»Ÿè®¡ç‰¹å¾ï¼Œçª—å£å¤§å°: {windows}")
    
    new_features_count = 0
    
    for col in target_cols:
        for window in windows:
            # ç§»åŠ¨å¹³å‡
            df[f'{col}_ma_{window}'] = df[col].rolling(window=window, min_periods=1).mean()
            
            # ç§»åŠ¨æ ‡å‡†å·®
            df[f'{col}_std_{window}'] = df[col].rolling(window=window, min_periods=1).std()
            
            # ç§»åŠ¨æœ€å¤§å€¼
            df[f'{col}_max_{window}'] = df[col].rolling(window=window, min_periods=1).max()
            
            # ç§»åŠ¨æœ€å°å€¼
            df[f'{col}_min_{window}'] = df[col].rolling(window=window, min_periods=1).min()
            
            # ç§»åŠ¨ä¸­ä½æ•°
            df[f'{col}_median_{window}'] = df[col].rolling(window=window, min_periods=1).median()
            
            new_features_count += 5
    
    print(f"âœ… ç»Ÿè®¡ç‰¹å¾åˆ›å»ºå®Œæˆï¼æ–°å¢ç‰¹å¾æ•°é‡: {new_features_count}")
    
    return df

def analyze_feature_correlations(df, target_cols, max_features=20):
    """åˆ†æç‰¹å¾ç›¸å…³æ€§"""
    print("\n" + "=" * 50)
    print("ğŸ”— åˆ†æç‰¹å¾ç›¸å…³æ€§")
    print("=" * 50)
    
    if not target_cols:
        print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡å˜é‡ï¼Œè·³è¿‡ç›¸å…³æ€§åˆ†æ")
        return
    
    # é€‰æ‹©æ•°å€¼å‹ç‰¹å¾
    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    
    # é™åˆ¶ç‰¹å¾æ•°é‡ä»¥é¿å…å†…å­˜é—®é¢˜
    if len(numeric_cols) > max_features:
        # ä¼˜å…ˆé€‰æ‹©ç›®æ ‡å˜é‡å’Œé‡è¦ç‰¹å¾
        important_cols = target_cols + [col for col in numeric_cols if 'lag_' in col or 'ma_' in col or 'std_' in col]
        selected_cols = list(set(important_cols))[:max_features]
        print(f"âš ï¸ ç‰¹å¾æ•°é‡è¿‡å¤šï¼Œé€‰æ‹©å‰{max_features}ä¸ªé‡è¦ç‰¹å¾è¿›è¡Œåˆ†æ")
    else:
        selected_cols = numeric_cols
    
    try:
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        correlation_matrix = df[selected_cols].corr()
        
        # åˆ›å»ºçƒ­åŠ›å›¾
        plt.figure(figsize=(16, 12))
        sns.heatmap(correlation_matrix, 
                   annot=True, 
                   cmap='coolwarm', 
                   center=0,
                   square=True,
                   fmt='.2f',
                   cbar_kws={'shrink': 0.8})
        
        plt.title('ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.show()
        
        # ä¿å­˜å›¾è¡¨
        plt.savefig('feature_correlations.png', dpi=300, bbox_inches='tight')
        print("ğŸ’¾ ç›¸å…³æ€§çƒ­åŠ›å›¾å·²ä¿å­˜ä¸º 'feature_correlations.png'")
        
        # åˆ†æç›®æ ‡å˜é‡çš„ç›¸å…³æ€§
        print("\nğŸ¯ ç›®æ ‡å˜é‡ç›¸å…³æ€§åˆ†æ:")
        for target in target_cols[:5]:  # åªåˆ†æå‰5ä¸ªç›®æ ‡å˜é‡
            if target in correlation_matrix.columns:
                correlations = correlation_matrix[target].abs().sort_values(ascending=False)
                print(f"\n{target} çš„ç›¸å…³æ€§æ’åº (å‰10ä¸ª):")
                print(correlations.head(10))
        
    except Exception as e:
        print(f"âŒ ç›¸å…³æ€§åˆ†æå¤±è´¥: {e}")

def evaluate_feature_quality(df, target_cols):
    """è¯„ä¼°ç‰¹å¾è´¨é‡"""
    print("\n" + "=" * 50)
    print("ğŸ“Š ç‰¹å¾è´¨é‡è¯„ä¼°")
    print("=" * 50)
    
    if not target_cols:
        print("âš ï¸ æœªæ‰¾åˆ°ç›®æ ‡å˜é‡ï¼Œè·³è¿‡ç‰¹å¾è´¨é‡è¯„ä¼°")
        return
    
    print("ğŸ” ç‰¹å¾è´¨é‡æŠ¥å‘Š:")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_features = len(df.columns)
    target_features = len(target_cols)
    engineered_features = total_features - target_features
    
    print(f"ğŸ“ˆ æ€»ç‰¹å¾æ•°é‡: {total_features}")
    print(f"ğŸ¯ ç›®æ ‡å˜é‡æ•°é‡: {target_features}")
    print(f"ğŸ”§ å·¥ç¨‹ç‰¹å¾æ•°é‡: {engineered_features}")
    
    # ç¼ºå¤±å€¼ç»Ÿè®¡
    missing_stats = df.isnull().sum()
    features_with_missing = missing_stats[missing_stats > 0]
    
    if len(features_with_missing) > 0:
        print(f"\nâš ï¸ æœ‰ç¼ºå¤±å€¼çš„ç‰¹å¾æ•°é‡: {len(features_with_missing)}")
        print("ç¼ºå¤±å€¼æœ€å¤šçš„ç‰¹å¾:")
        print(features_with_missing.head().to_dict())
    else:
        print("\nâœ… æ‰€æœ‰ç‰¹å¾éƒ½æ²¡æœ‰ç¼ºå¤±å€¼")
    
    # ç‰¹å¾ç±»å‹åˆ†å¸ƒ
    print(f"\nğŸ“‹ ç‰¹å¾ç±»å‹åˆ†å¸ƒ:")
    print(df.dtypes.value_counts())

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ å•†å“é¢„æµ‹æŒ‘æˆ˜èµ› - å°ç™½å­¦ä¹ æŒ‡å—")
    print("ğŸ“š ç¬¬äºŒé˜¶æ®µï¼šç‰¹å¾å·¥ç¨‹")
    print("=" * 60)
    
    # åŠ è½½æ•°æ®
    df = load_data()
    if df is None:
        return
    
    # è·å–ç›®æ ‡å˜é‡åˆ—
    target_columns = [col for col in df.columns if col.startswith('target_')]
    print(f"ğŸ¯ æ‰¾åˆ° {len(target_columns)} ä¸ªç›®æ ‡å˜é‡")
    
    # ä»»åŠ¡1ï¼šåˆ›å»ºæ—¶é—´ç‰¹å¾
    df = create_time_features(df)
    
    # ä»»åŠ¡2ï¼šåˆ›å»ºæ»åç‰¹å¾
    df = create_lag_features(df, target_columns)
    
    # é¢å¤–ä»»åŠ¡ï¼šåˆ›å»ºç»Ÿè®¡ç‰¹å¾
    df = create_statistical_features(df, target_columns)
    
    # åˆ†æç‰¹å¾ç›¸å…³æ€§
    analyze_feature_correlations(df, target_columns)
    
    # è¯„ä¼°ç‰¹å¾è´¨é‡
    evaluate_feature_quality(df, target_columns)
    
    # ä¿å­˜å¤„ç†åçš„æ•°æ®
    output_file = 'train_labels_with_features.csv'
    df.to_csv(output_file, index=False)
    print(f"\nğŸ’¾ å¤„ç†åçš„æ•°æ®å·²ä¿å­˜ä¸º '{output_file}'")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ ç¬¬äºŒé˜¶æ®µå­¦ä¹ ä»»åŠ¡å®Œæˆï¼")
    print("ğŸ“ æ¥ä¸‹æ¥ä½ å¯ä»¥ï¼š")
    print("   1. æŸ¥çœ‹ç‰¹å¾ç›¸å…³æ€§çƒ­åŠ›å›¾")
    print("   2. åˆ†æå“ªäº›ç‰¹å¾æœ€æœ‰ä»·å€¼")
    print("   3. å‡†å¤‡è¿›å…¥ç¬¬ä¸‰é˜¶æ®µï¼šæ¨¡å‹è®­ç»ƒ")
    print("=" * 60)

if __name__ == "__main__":
    main()
